<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RealtimeAPI</title>
</head>

<body>
    <h1>RealtimeAPI</h1>
    <!-- <input type="text" id="input" placeholder="メッセージを入力してください" />
    <button id="chat-button">送信</button> -->

    <div id="response"></div>

    <script>
        // WebSocket 接続
        // const socket = new WebSocket("ws://localhost:8080/ws/realtime");
        const socket = new WebSocket("wss://api.kaisetsu-chat.com/ws/realtime");

        // WebSocket が開かれたとき
        socket.onopen = () => {
            console.log("WebSocket 接続完了");

            // 設定値を送信する
            const data = {
                "apikey": "fjoagjaoghso",
                "room_id": "101",
                "comp_id": "87",
                "user_id": "87",
                "sessid": "",
                "sample_rate": "48000"
            };
            socket.send(JSON.stringify(data));
        };

        const responseDiv = document.getElementById('response');

        const audioContext = new (window.AudioContext || window.webkitAudioContext)();

        // 音声データのキュー
        const audioQueue = [];

        // 再生中かどうかのフラグ
        let isPlaying = false;

        let responseDone = true;

        // WebSocket からメッセージを受け取ったとき
        socket.onmessage = (event) => {
            const response = event.data;          
            response_data = JSON.parse(response)
            // console.log(response_data);

            if (response_data['type']=="response_audio") {
                const base64String = response_data['content']; // Base64エンコードされた音声データ
                const byteCharacters = atob(base64String); // Base64文字列をバイナリ文字列にデコード
                const byteArray = new Uint8Array(byteCharacters.length);

                // バイナリ文字列をUint8Arrayに変換
                for (let i = 0; i < byteCharacters.length; i++) {
                    byteArray[i] = byteCharacters.charCodeAt(i);
                }

                // ArrayBufferを生成
                const arrayBuffer = byteArray.buffer;

                // 変換したArrayBufferを音声再生関数に渡す
                enqueueAudio(arrayBuffer);
            }

            if (response_data['type']=="response_text") {
                if (response_data['content'] == 'response.audio_transcript.done') {
                    responseDone = true;
                } else {
                    if (responseDone) {
                        responseDiv.innerHTML += "<br>【アシスタント】: " + response_data['content'];
                        responseDone = false;
                    } else {
                        responseDiv.innerHTML += response_data['content'];
                    }
                }
            }

            if (response_data['type']=="input_text") {
                console.log(response_data['content']);
                // responseDiv.innerHTML += "<br>【あなた】: " + response_data['content'];
            }
        };

        // PCM16データをキューに追加
        function enqueueAudio(buffer) {
            audioQueue.push(buffer);
            if (!isPlaying) {
                playNextAudio();
            }
        }

        // 次の音声を再生
        function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }

            // キューから音声データを取り出し
            const pcmData = audioQueue.shift();
            isPlaying = true;
            playPCM16(pcmData).then(() => {
                playNextAudio(); // 再生が終わったら次を再生
            }).catch((error) => {
                console.error('Error playing PCM16 data:', error);
                playNextAudio(); // エラーが発生しても次の再生に進む
            });
        }

        // PCM16データをAudioBufferに変換して再生
        function playPCM16(pcmData, delayTime = 0.5) {
            return new Promise((resolve, reject) => {
                // PCM16データをAudioBufferに変換して再生
                decodePCM16ToAudioBuffer2(pcmData).then(audioBuffer => {
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;

                    // 再生開始を遅らせる
                    // const startTime = audioContext.currentTime + delayTime;
                    const startTime = audioContext.currentTime;
                    source.start(startTime);

                    source.connect(audioContext.destination);
                    // source.onended = resolve; // 再生が終了したら次の処理を実行
                    source.onended = () => {
                        isPlaying = false;  // 再生が終了したら、isPlayingをfalseに設定
                        resolve();
                    };
                }).catch(error => {
                    reject(error);
                });
            });
        }

        function decodePCM16ToAudioBuffer2(pcmData) {
            return new Promise((resolve, reject) => {
                try {
                    // PCM16データをInt16Arrayとして扱う
                    const int16Array = new Int16Array(pcmData);
                    const bufferLength = int16Array.length;  // PCMデータの長さ

                    // AudioBufferの作成。モノラル(1チャンネル)で、サンプル数はPCMデータの長さ、サンプルレートはAudioContextのレートに設定
                    const audioBuffer = audioContext.createBuffer(1, bufferLength, 24000); // サンプルレート24000Hz

                    // AudioBufferのチャンネルにデータを書き込む
                    const channelData = audioBuffer.getChannelData(0);

                    // PCM16は-32768～32767の範囲なので、-1～1に正規化
                    for (let i = 0; i < bufferLength; i++) {
                        channelData[i] = int16Array[i] / 32768;
                    }

                    // 正常に処理が完了したら、AudioBufferを解決
                    resolve(audioBuffer);
                } catch (error) {
                    // エラーハンドリング
                    reject(error);
                }
            });
        }

        // マイク音声をキャプチャする設定
        const constraints = {
            audio: true,
            video: false
        };

        // マイク音声をキャプチャしてWebSocketで送信する
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const analyser = audioContext.createAnalyser();
                const microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);

                // AudioBufferを取得するためのScriptProcessorNodeを作成
                const scriptProcessorNode = audioContext.createScriptProcessor(2048, 1, 1);
                analyser.connect(scriptProcessorNode);
                scriptProcessorNode.connect(audioContext.destination);  // 出力先に接続

                // PCMデータに変換する関数
                const convertTo16BitPCM = (buffer) => {
                    const pcmData = new Int16Array(buffer.length);
                    for (let i = 0; i < buffer.length; i++) {
                        pcmData[i] = Math.max(-32768, Math.min(32767, buffer[i] * 32768)); // -32768 ~ 32767 の範囲にスケーリング
                    }
                    return pcmData.buffer; // ArrayBufferを返す
                };
                
                // Base64エンコードする関数
                const encodeBase64 = (arrayBuffer) => {
                    const byteArray = new Uint8Array(arrayBuffer);
                    let binary = '';
                    for (let i = 0; i < byteArray.length; i++) {
                        binary += String.fromCharCode(byteArray[i]);
                    }
                    return btoa(binary);  // base64エンコード
                };

                // 音声データを取得して送信
                scriptProcessorNode.onaudioprocess = (event) => {
                    const inputBuffer = event.inputBuffer;  // 音声の入力バッファ
                    const channelData = inputBuffer.getChannelData(0);  // 1チャンネルのデータを取得（モノラル）

                    // PCMデータに変換
                    const pcmData = convertTo16BitPCM(channelData);
                    
                    // PCMデータをBase64エンコード
                    const base64EncodedData = encodeBase64(pcmData);

                    // WebSocket接続が開かれている場合、PCMデータを送信
                    if (socket.readyState === WebSocket.OPEN) {
                        console.log('音声送信');
                        //socket.send(pcmData);
                        socket.send(base64EncodedData);
                    }
                };

            })
            .catch(err => {
                console.error('Error accessing media devices.', err);
            });
        

        // WebSocket接続が閉じられたときの処理
        socket.onclose = () => {
            console.log('WebSocket connection closed');
        };

        // WebSocket接続中にエラーが発生した場合
        socket.onerror = (error) => {
            console.error('WebSocket Error:', error);
        };

    </script>
</body>

</html>